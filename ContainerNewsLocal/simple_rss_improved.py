#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ RSS —Å–∫—Ä–∏–ø—Ç–∞
–ë–µ–∑ –æ—à–∏–±–æ–∫ datetime –∏ —Å –ª—É—á—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
"""

import feedparser
import requests
from datetime import datetime, timezone
import time

RSS_SOURCES = [
    # Kubernetes official
    "https://kubernetes.io/feed.xml",
    "https://github.com/kubernetes/kubernetes/releases.atom",
    "https://github.com/kubernetes/minikube/releases.atom",
    "https://github.com/kubernetes-sigs/kind/releases.atom",
    "https://github.com/k3s-io/k3s/releases.atom",

    # Docker official
    "https://www.docker.com/blog/feed/",
    "https://github.com/docker/docker-ce/releases.atom",
    "https://github.com/docker/cli/releases.atom",
    "https://github.com/moby/moby/releases.atom",
    "https://github.com/docker/compose/releases.atom",

    # Podman, containers
    "https://github.com/containers/podman/releases.atom",
    "https://github.com/containers/buildah/releases.atom",
    "https://github.com/containers/skopeo/releases.atom",
    "https://github.com/cri-o/cri-o/releases.atom",

    # Container infrastructure engines
    "https://github.com/containerd/containerd/releases.atom",
    "https://github.com/opencontainers/runc/releases.atom",
    "https://github.com/opencontainers/image-spec/releases.atom",

    # Community/aggregators
    "https://habr.com/ru/rss/search/?q=docker+podman+–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã&target_type=posts",
    "https://dev.to/feed/tag/docker",
    "https://dev.to/feed/tag/container",
    "https://dev.to/feed/tag/kubernetes"
]

def parse_date_safe(date_str):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã"""
    if not date_str:
        return datetime.now(timezone.utc)
    
    try:
        # feedparser –æ–±—ã—á–Ω–æ –ø–∞—Ä—Å–∏—Ç –¥–∞—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        if hasattr(date_str, 'tm_year'):  # struct_time
            return datetime(*date_str[:6], tzinfo=timezone.utc)
        return datetime.now(timezone.utc)
    except:
        return datetime.now(timezone.utc)

def fetch_rss_news():
    news = []
    success_count = 0
    error_count = 0
    
    print(f"üöÄ –ù–∞—á–∏–Ω–∞—é —Å–±–æ—Ä –∏–∑ {len(RSS_SOURCES)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
    
    for i, url in enumerate(RSS_SOURCES, 1):
        print(f"[{i}/{len(RSS_SOURCES)}] {url}")
        
        try:
            headers = {
                'User-Agent': 'SimpleRSSCollector/1.0'
            }
            response = requests.get(url, timeout=(10, 30), headers=headers)
            response.raise_for_status()
            
            feed = feedparser.parse(response.content)
            
            if feed.bozo:
                print(f"  ‚ö†Ô∏è  –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π RSS")
            
            entry_count = 0
            for entry in feed.entries[:5]:  # –¢–æ–ª—å–∫–æ 5 –∑–∞–ø–∏—Å–µ–π –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫
                pub_date = parse_date_safe(entry.get("published_parsed"))
                
                news.append({
                    "title": entry.title,
                    "link": entry.link,
                    "date": pub_date.strftime("%Y-%m-%d %H:%M"),
                    "date_obj": pub_date,
                    "summary": entry.get("summary", "")[:200] + "...",
                    "source": url.split('/')[2]  # –î–æ–º–µ–Ω –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                })
                entry_count += 1
            
            print(f"  ‚úÖ {entry_count} –Ω–æ–≤–æ—Å—Ç–µ–π")
            success_count += 1
            time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            
        except requests.exceptions.Timeout:
            print(f"  ‚è∞ Timeout")
            error_count += 1
        except requests.exceptions.ConnectionError:
            print(f"  üîå Connection error")  
            error_count += 1
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
            error_count += 1
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: ‚úÖ{success_count} ‚ùå{error_count}")
    return news

def filter_recent_news(news_list, hours=24):
    """–§–∏–ª—å—Ç—Ä —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
    now = datetime.now(timezone.utc)
    recent = []
    
    for item in news_list:
        if (now - item['date_obj']).total_seconds() < hours * 3600:
            recent.append(item)
    
    return sorted(recent, key=lambda x: x['date_obj'], reverse=True)

if __name__ == "__main__":
    try:
        print("=== üì∞ Container Technologies News Collector ===\n")
        
        news_list = fetch_rss_news()
        print(f"\nüì∞ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ: {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        # –§–∏–ª—å—Ç—Ä —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞)
        recent_news = filter_recent_news(news_list, hours=24)
        print(f"üî• –°–≤–µ–∂–∏–µ (24—á): {len(recent_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        print("\n=== üî• –°–í–ï–ñ–ò–ï –ù–û–í–û–°–¢–ò ===")
        for item in recent_news[:10]:
            print(f"üìÖ {item['date']}")
            print(f"üì∞ {item['title']}")
            print(f"üîó {item['link']}")
            print(f"üåê {item['source']}")
            print(f"üìù {item['summary']}")
            print("-" * 80)
            
    except Exception as e:
        print(f"‚ùå –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")